{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoding: utf-8\n",
    "import json\n",
    "from pprint import pprint\n",
    "def address(file_name):\n",
    "    with open(file_name) as fp:\n",
    "        data = json.load(fp)\n",
    "    order_attributes = data['order_attributes']\n",
    "    address_name = []\n",
    "    for attr in order_attributes:\n",
    "        if attr['attr_id'] == 158:\n",
    "            address_name.append(attr['attr_value'])\n",
    "    return address_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time of process\n",
    "from ltpout import AddressDrinkParser\n",
    "from time import time\n",
    "start = time()\n",
    "import chardet\n",
    "address_drink_parser = AddressDrinkParser()\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "深南大道\n",
      "0.273422956467\n",
      "0.00159096717834\n"
     ]
    }
   ],
   "source": [
    "start1 = time()\n",
    "sentence = '送到深南大道'\n",
    "solution = address_drink_parser.get_address(sentence)\n",
    "end1 = time()\n",
    "for temp in solution:\n",
    "    print(temp)\n",
    "print(end-start)  # time to load modules\n",
    "print(end1-start1)   # time to process sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "东四北大街107号科林大厦，B座107室\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regular = re.compile(r\"[' '\\-()/]\")\n",
    "print ''.join(regular.split('东四北大街107号/科林大厦，B座107室'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851540616246\n"
     ]
    }
   ],
   "source": [
    "# accuracy to recognize the whole address when given an address\n",
    "right_count = 0.0\n",
    "total_count = 0.0\n",
    "\n",
    "for i in range(11001,16000):\n",
    "    file_name = '/home/zhongtao/pyltp/coffee/19April2016/order_conversation/'+str(i)\n",
    "    #print file_name\n",
    "    #print file_name\n",
    "    address_name = address(file_name)\n",
    "    for name in address_name:\n",
    "        #print name\n",
    "        total_count += 1\n",
    "        name = ''.join(regular.split(name))\n",
    "        \n",
    "        solution = address_drink_parser.get_address(name.encode('utf-8'))\n",
    "        \n",
    "        if len(solution) == 0:\n",
    "            #print name\n",
    "            #print '\\n'\n",
    "            pass\n",
    "        elif solution[0].decode('utf-8') != name:\n",
    "            #print name\n",
    "            for temp in solution:\n",
    "                #print temp\n",
    "                pass\n",
    "            #print '\\n'\n",
    "        else:\n",
    "            right_count +=1\n",
    "print(right_count/total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "def message(file_name):\n",
    "    with open(file_name) as fp:\n",
    "        data = json.load(fp)\n",
    "    #print file_name\n",
    "    order_attributes = data['conversation']\n",
    "    #print order_attributes\n",
    "    conversation = []\n",
    "    for conver in order_attributes:\n",
    "        #＃print conver\n",
    "        soup = BeautifulSoup(conver['msg'], 'lxml')\n",
    "        name = soup.get_text()\n",
    "        #print name\n",
    "        conversation.append(name)\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(3204)\n",
    "conversation = message(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name in conversation:\n",
    "    #print name\n",
    "    solution = address_drink_parser.get_address(name.encode('utf-8'))\n",
    "    \n",
    "    for temp in solution:\n",
    "        #print('1:'+temp)\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3204\n",
      "西单国际大厦11层\n",
      "南新仓大厦B座11层1116\n"
     ]
    }
   ],
   "source": [
    "for i in range(3204,3205):\n",
    "    file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(i)\n",
    "    conversation = message(file_name)\n",
    "    print i\n",
    "    for name in conversation:    \n",
    "        solution = address_drink_parser.get_address(name.encode('utf-8'))\n",
    "        for temp in solution:\n",
    "            print(temp)\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://r.ele.me/jmxzw\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:198: UserWarning: \"coffee\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://waimai.baidu.com/waimai/shop/1447683483\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://m.lyancoffee.com/wechat/address/base/selected/134691\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:198: UserWarning: \"/\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://bj.1010jz.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939781410036\n"
     ]
    }
   ],
   "source": [
    "# accuracy to extract the address when given one sentence\n",
    "right_count = 0.0\n",
    "total_count = 0.0\n",
    "import re\n",
    "for i in range(3001,10000):\n",
    "    file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(i)\n",
    "    conversation = message(file_name)\n",
    "    address_name = address(file_name)\n",
    "    #print i\n",
    "    for name in conversation:\n",
    "        #print name\n",
    "        total_count += 1\n",
    "        for address_temp in address_name:\n",
    "            address_temp = ''.join(regular.split(address_temp))\n",
    "            name = ''.join(regular.split(name))\n",
    "            regu = re.compile(address_temp)\n",
    "            if regu.search(name):\n",
    "                out = address_temp\n",
    "            else:\n",
    "                out = ''\n",
    "        \n",
    "        solution = address_drink_parser.get_address(name.encode('utf-8'))\n",
    "        \n",
    "        if not solution and not out:\n",
    "            right_count += 1\n",
    "        elif solution and out and solution[0].decode('utf-8') == out:\n",
    "            right_count += 1\n",
    "        else:\n",
    "            #print int(total_count)\n",
    "            if solution:\n",
    "                #print '1:'+solution[0]\n",
    "                pass\n",
    "            if out:\n",
    "                #print '2:'+out\n",
    "                pass\n",
    "print right_count/total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://mp.weixin.qq.com/s?__biz=MzAxMjU4MDQ1Mg==&mid=403712975&idx=2&sn=356431651578846e7f183621b979e39e&scene=1&srcid=11116gWIaYpoWXL033u3NJ1t#wechat_redirect\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://waimai.baidu.com/waimai/shop/1430637499\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650285212813\n"
     ]
    }
   ],
   "source": [
    "# accuracy to extract the address when given a sentence with an address\n",
    "right_count = 0.0\n",
    "total_count = 0.0\n",
    "import re\n",
    "for i in range(13000,18000):\n",
    "    file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(i)\n",
    "    conversation = message(file_name)\n",
    "    address_name = address(file_name)\n",
    "    #print i\n",
    "    for name in conversation:\n",
    "        for address_temp in address_name:\n",
    "            address_temp = ''.join(regular.split(address_temp))\n",
    "            name = ''.join(regular.split(name))\n",
    "            regu = re.compile(address_temp)\n",
    "            if regu.search(name):\n",
    "                total_count += 1\n",
    "                out = address_temp\n",
    "                out = ''.join(regular.split(out))\n",
    "\n",
    "                solution = address_drink_parser.get_address(name.encode('utf-8'))\n",
    "                if solution and out and solution[0].decode('utf-8') == out:\n",
    "                    right_count += 1\n",
    "                else:\n",
    "                    if solution:\n",
    "                        #print '1:'+solution[0]\n",
    "                        pass\n",
    "                    #print '2:'+out\n",
    "print right_count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def product(file_name):\n",
    "    with open(file_name) as fp:\n",
    "        data = json.load(fp)\n",
    "    order_attributes = data['order_attributes']\n",
    "    address_name = []\n",
    "    for attr in order_attributes:\n",
    "        if attr['attr_id'] == 156:\n",
    "            address_name.append(attr['attr_value'])\n",
    "    return address_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def message(file_name):\n",
    "    with open(file_name) as fp:\n",
    "        data = json.load(fp)\n",
    "    #print file_name\n",
    "    order_attributes = data['conversation']\n",
    "    #print order_attributes\n",
    "    conversation = []\n",
    "    for conver in order_attributes:\n",
    "        #＃print conver\n",
    "        soup = BeautifulSoup(conver['msg'], 'lxml')\n",
    "        name = soup.get_text()\n",
    "        #print name\n",
    "        conversation.append(name)\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time of process\n",
    "from ltpout import AddressDrinkParser\n",
    "from time import time\n",
    "start = time()\n",
    "import chardet\n",
    "address_drink_parser = AddressDrinkParser()\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = '/home/zhongtao/pyltp/coffee/19April2016/order_conversation/'+str(4758)\n",
    "conversation = message(file_name)\n",
    "for name in conversation:\n",
    "    #pass\n",
    "    #print name\n",
    "    #words, postags, arcs = parse_sentence(segmentor, postagger, parser, name.encode('utf-8'))\n",
    "    solution = address_drink_parser.get_drink(name.encode('utf-8'))\n",
    "    for temp in solution:\n",
    "        #print('1:'+temp)\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "for i in range(1,35000):\n",
    "    file_name = '/home/zhongtao/pyltp/coffee/19April2016/order_conversation/'+str(i)\n",
    "    #print file_name\n",
    "    #print file_name\n",
    "    #＃print i\n",
    "    product_name = product(file_name)\n",
    "    for name in product_name:\n",
    "        #＃print '1:'+name\n",
    "        #name = ''.join(regular.split(name))\n",
    "        #words, postags, arcs = parse_sentence(segmentor, postagger, parser, name.encode('utf-8'))\n",
    "        solution = address_drink_parser.get_drink(name.encode('utf-8'))\n",
    "        #＃print '2:'\n",
    "        if len(solution) == 0:\n",
    "            #print '1:'+name\n",
    "            for temp in solution:\n",
    "                #print temp\n",
    "                pass\n",
    "    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://www.namoc.org/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://r.ele.me/hq-bhkpizza\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://r.ele.me/hp-sbzp1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for i in range(1,3000):\n",
    "    #print str(i) + '---------------'\n",
    "    file_name = '/home/zhongtao/pyltp/coffee/19April2016/order_conversation/'+str(i)\n",
    "    conversation = message(file_name)\n",
    "    for name in conversation:\n",
    "        #print name\n",
    "        #＃words, postags, arcs = parse_sentence(segmentor, postagger, parser, name.encode('utf-8'))\n",
    "        solution = address_drink_parser.get_drink(name.encode('utf-8'))\n",
    "        if len(solution) != 0:\n",
    "            #print('1:'+name)\n",
    "            pass\n",
    "        for temp in solution:\n",
    "            pass\n",
    "            #print('2:'+temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "file_name = '/home/zhongtao/pyltp/coffee/19April2016/sku_id.txt'\n",
    "with open(file_name, 'r') as fp:\n",
    "    data = fp.readlines()\n",
    "for name in data:\n",
    "    name = name.strip('\\n')\n",
    "    #words, postags, arcs = parse_sentence(segmentor, postagger, parser, name)\n",
    "    #solution = drink_extract(words, postags, arcs)\n",
    "    solution = address_drink_parser.get_drink(name)\n",
    "    #print ('1:'+name)\n",
    "    count1 += 1\n",
    "    for temp in solution:\n",
    "        #print('2:'+temp)\n",
    "        count2 += 1\n",
    "        pass\n",
    "print count1\n",
    "print count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
